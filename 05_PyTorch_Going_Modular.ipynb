{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyONWbAj1QcB08d4jhhWnbmA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nmermigas/PyTorch/blob/main/05_PyTorch_Going_Modular.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Overview:\n",
        "\n",
        "In this section, we will use a condensed version of the 04_custom_datasets notebook and will try to run it in a script mode.\n",
        "\n",
        "What follows is the code of the notebook 04."
      ],
      "metadata": {
        "id": "WOBEbjZeqGzN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Get Data"
      ],
      "metadata": {
        "id": "96rKQbS4r4AA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "\n",
        "# Setup path to data folder\n",
        "data_path = Path(\"data/\")\n",
        "image_path = data_path / \"pizza_steak_sushi\"\n",
        "\n",
        "# If the image folder doesn't exist, download it and prepare it...\n",
        "if image_path.is_dir():\n",
        "    print(f\"{image_path} directory exists.\")\n",
        "else:\n",
        "    print(f\"Did not find {image_path} directory, creating one...\")\n",
        "    image_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Download pizza, steak, sushi data\n",
        "with open(data_path / \"pizza_steak_sushi.zip\", \"wb\") as f:\n",
        "    request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n",
        "    print(\"Downloading pizza, steak, sushi data...\")\n",
        "    f.write(request.content)\n",
        "\n",
        "# Unzip pizza, steak, sushi data\n",
        "with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\", \"r\") as zip_ref:\n",
        "    print(\"Unzipping pizza, steak, sushi data...\")\n",
        "    zip_ref.extractall(image_path)\n",
        "\n",
        "# Remove zip file\n",
        "os.remove(data_path / \"pizza_steak_sushi.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JM7a1WyjsX9K",
        "outputId": "bbb61380-3b42-44cc-e91f-1f0c94c4fce5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Did not find data/pizza_steak_sushi directory, creating one...\n",
            "Downloading pizza, steak, sushi data...\n",
            "Unzipping pizza, steak, sushi data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Setup train and testing paths\n",
        "train_dir = image_path/\"train\"\n",
        "test_dir = image_path / \"test\""
      ],
      "metadata": {
        "id": "6TqDCy_y0QwE"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Write a transform for image\n",
        "data_transform = transforms.Compose([\n",
        "    # Resize our images to 64x64\n",
        "    transforms.Resize(size=(64,64)),\n",
        "    # Flip the images randomly on the horizontal\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    # Turn the image into a torch.Tensor\n",
        "    transforms.ToTensor()\n",
        "])"
      ],
      "metadata": {
        "id": "hHbWT7X30h9U"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Create Datasets and DataLoaders (script mode)\n",
        "\n",
        "Let's use the jupyter magic function to create a `.py` file for creating DataLoaders.\n",
        "\n",
        "We can save a code cell's contents to a file using the Jupyter magic `%%magicfile filename`."
      ],
      "metadata": {
        "id": "Rqz8BeA4sYgb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a directory for going modular scripts\n",
        "import os\n",
        "os.makedirs('going_modular')"
      ],
      "metadata": {
        "id": "fzhGBF5Fuffz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile going_modular/data_setup.py\n",
        "\n",
        "\"\"\"\n",
        "Contains functionality for creating PyTorch DataLoaders for\n",
        "image classification data.\n",
        "\n",
        "\"\"\"\n",
        "import os\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "NUM_WORKERS = os.cpu_count()\n",
        "\n",
        "def create_dataloaders(\n",
        "  train_dir:str,\n",
        "  test_dir:str,\n",
        "  transform: transforms.Compose,\n",
        "  batch_size:int,\n",
        "  num_workers = NUM_WORKERS\n",
        "):\n",
        "  \"\"\" Creates training and test DataLoaders.\n",
        "  Takes in a training directory and testing directory path\n",
        "  and turns them into PyTorch Datasets and then into PyTorch DataLoaders.\n",
        "\n",
        "  Args:\n",
        "    train_dir: Path to training directory.\n",
        "    test_dir: Path to testing directory.\n",
        "    transform: torchvision transforms to perform on training and testing data.\n",
        "    batch_size: Number of samples per batch in each of the DataLoaders.\n",
        "    num_workers: An integer for number of workers per DataLoader\n",
        "\n",
        "  Returns:\n",
        "    A tuple of (train_dataloader, test_dataloader, class_names).\n",
        "    Where class_names is a list of the target classes.\n",
        "    Example usage:\n",
        "      train_dataloader, test_dataloader, class_names = create_dataloaders(train_dir,\n",
        "        test_dir,transform, batch_size, num_workers)\n",
        "\n",
        "  \"\"\"\n",
        "  # Use ImageFolder to create datasets\n",
        "  train_data = datasets.ImageFolder(train_dir, transform = transform)\n",
        "  test_data = datasets.ImageFolder(test_dir, transform = transform)\n",
        "\n",
        "  # Get class names\n",
        "  class_names = train_data.classes\n",
        "\n",
        "  # Turn datasets into DataLoaders\n",
        "  train_dataloader = DataLoader(\n",
        "      train_data,\n",
        "      batch_size = batch_size,\n",
        "      shuffle = True,\n",
        "      pin_memory=True,\n",
        "      num_workers = num_workers\n",
        "  )\n",
        "\n",
        "  test_dataloader = DataLoader(\n",
        "      test_data,\n",
        "      batch_size = batch_size,\n",
        "      shuffle = False,\n",
        "      pin_memory=True,\n",
        "      num_workers = num_workers\n",
        "  )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  return train_dataloader, test_dataloader, class_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5myr_F9tQq0",
        "outputId": "555df346-c923-4c98-9219-a96dc2a20760"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting going_modular/data_setup.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from going_modular import data_setup\n",
        "\n",
        "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(train_dir = train_dir,\n",
        "                                                                               test_dir = test_dir,\n",
        "                                                                               transform = data_transform,\n",
        "                                                                               batch_size = 32,\n",
        "                                                                               num_workers = 2)\n",
        "print(train_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBxlAWGPt4nN",
        "outputId": "ae804e64-9435-44de-992b-90f0c6094ec2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<torch.utils.data.dataloader.DataLoader object at 0x7d5dfbfee4a0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a7neN7Kd0qC8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}